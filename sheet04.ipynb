{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 4\n",
    "## 3 K-Nearest Neighbors: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for faster runtimes, we use a subsampled version of the data even as the 'full' dataset\n",
    "full_features = np.load('data/dijet_features_normalized.npy')[:, ::2]\n",
    "full_labels = np.load('data/dijet_labels.npy')[::2]\n",
    "\n",
    "dset_full = (full_features, full_labels) \n",
    "dset_medium = (full_features[:, ::4], full_labels[::4])\n",
    "dset_small = (full_features[:, ::16], full_labels[::16])\n",
    "dsets = (dset_small, dset_medium, dset_full)\n",
    "\n",
    "for features, labels in dsets:\n",
    "    print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval_splits(features, labels, k):\n",
    "    \"\"\"\n",
    "    compute k-fold cross valditaion splits of the features and corresponding labels\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features : np.ndarray\n",
    "        Feature array of shape (d, N).\n",
    "    labels : np.ndarray\n",
    "        Label array of shape (N).\n",
    "    n : int\n",
    "        Number of folds.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of the cross validation splits, i.e. a list splits of length n\n",
    "        splits[i] = ((training_features_i, training_labels_i), (val_features_i, val_labels_i)).\n",
    "        \n",
    "    \"\"\"\n",
    "    assert features.shape[-1] == len(labels), f'Shape mismatch: {features.shape}, {labels.shape}'\n",
    "    \n",
    "    # TODO: divide features and labels into (approximately) equal sized chunks\n",
    "    # Hint: Use np.linspace to get chunk borders and round the results\n",
    "    \n",
    "    # TODO: Shuffle the data\n",
    "    \n",
    "    # TODO: Construct a list consisting of the splits; each split consits of \n",
    "    #       - the validation set (one chunk of the features and corresponding labels) \n",
    "    #       - the training training set (concatenation of all feature and label chunks not used for validation)\n",
    "    # i.e. splits[i] = ((training_features_i, training_labels_i), (val_features_i, val_labels_i))\n",
    "    \n",
    "    assert len(splits) == n, f'Got incorrect number of splits: {len(splits)=}!={n=}'\n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_err(pred, labels):\n",
    "    \"\"\"mean error between categorical predictions and labels (each a 1D numpy array)\"\"\"\n",
    "    # TODO implement this (Hint: compute the mean over a fitting boolean array)\n",
    "    err = \n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "ks = (1, 3, 5, 10, 20, 30, 50)\n",
    "n_folds = 10\n",
    "errors = np.empty(n_folds, len(ks))\n",
    "\n",
    "for i, ((train_features, train_labels), (val_features, val_labels)) in enumerate(crossval_splits(features_full, labels_full, n_folds)): \n",
    "    for j, k in enumerate(ks):\n",
    "        # TODO: Use KNeighborsClassifier from sklearn (read the documentation) to fit the training data and save the validation error\n",
    "        \n",
    "        scores[i, j] =  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "ks = (1, 3, 5, 10, 20, 30, 50)\n",
    "n_folds = 10\n",
    "errors = np.empty((len(dsets), n_folds, len(ks)))\n",
    "\n",
    "for i, (features, labels) in enumerate(dsets):\n",
    "    print(f'Dataset size {len(labels)}')\n",
    "    for j, ((train_features, train_labels), (val_features, val_labels)) in enumerate(crossval_splits(features, labels, n_folds)):\n",
    "        for l, k in enumerate(ks):\n",
    "            # TODO: Use KNeighborsClassifier from sklearn (read the documentation) to fit the training data and save the validation error\n",
    "\n",
    "            scores[i, j, l] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make and interpret the plots as requested in the exercise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
